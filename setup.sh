#!/bin/bash

# ==========================================
# ğŸš€ SETUP GOD MODE : AGENT KERNEL + UI
# ==========================================

PROJECT_NAME="agent_kernel"
MODEL_NAME="qwen2.5-coder:1.5b" # ModÃ¨le lÃ©ger et puissant pour le code

echo "ğŸŒ Initialisation de l'architecture $PROJECT_NAME..."

# --- 1. PRÃ‰PARATION DE L'HÃ”TE (GITHUB CODESPACE) ---
echo "ğŸ› ï¸  Mise Ã  jour de l'hÃ´te..."
sudo apt-get update > /dev/null 2>&1
sudo apt-get install -y pciutils lshw > /dev/null 2>&1 # Utiles pour debug matÃ©riel

# --- 2. CONSTRUCTION DU KERNEL (ISOLATION) ---
# On vÃ©rifie si on est dans le bon dossier, sinon on le crÃ©e
if [ "${PWD##*/}" != "$PROJECT_NAME" ]; then
    mkdir -p $PROJECT_NAME
    cd $PROJECT_NAME
fi

echo "ğŸ§¹ Nettoyage et Reconstruction du RootFS..."
sudo rm -rf rootfs alpine.tar.gz
mkdir rootfs
curl -s -o alpine.tar.gz https://dl-cdn.alpinelinux.org/alpine/v3.18/releases/x86_64/alpine-minirootfs-3.18.4-x86_64.tar.gz
tar -xzf alpine.tar.gz -C rootfs

# Configuration DNS & Python dans la "prison"
echo "ğŸ“¦ Injection des outils dans le Kernel..."
sudo cp /etc/resolv.conf rootfs/etc/resolv.conf
sudo chroot rootfs /bin/sh -c "
    apk add --no-cache python3 py3-pip > /dev/null 2>&1 &&
    pip install --no-cache-dir --upgrade pip > /dev/null 2>&1 &&
    pip install --no-cache-dir hyperliquid-python-sdk requests > /dev/null 2>&1
"

# CrÃ©ation du script de santÃ© interne
cat <<EOF | sudo tee rootfs/home/health_check.py > /dev/null
import sys
try:
    import hyperliquid
    import requests
    print("âœ… SYSTEME INTERNE OPÃ‰RATIONNEL")
except ImportError as e:
    print(f"âŒ ERREUR CRITIQUE : {e}")
EOF

# --- 3. INSTALLATION DU CERVEAU (OLLAMA) ---
if ! command -v ollama &> /dev/null; then
    echo "ğŸ¤– Installation d'Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh > /dev/null 2>&1
else
    echo "ğŸ¤– Ollama est dÃ©jÃ  installÃ©."
fi

# DÃ©marrage du serveur Ollama en arriÃ¨re-plan
echo "ğŸ§  DÃ©marrage du moteur neuronal..."
ollama serve > /dev/null 2>&1 &
PID_OLLAMA=$!
sleep 5 # On laisse le temps au serveur de dÃ©marrer

# TÃ©lÃ©chargement du modÃ¨le (si absent)
echo "ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le $MODEL_NAME (peut prendre 1-2 min)..."
ollama pull $MODEL_NAME > /dev/null 2>&1

# --- 4. CRÃ‰ATION DE L'INTERFACE STREAMLIT ---
echo "ğŸ¨ GÃ©nÃ©ration du Dashboard de contrÃ´le..."
pip install streamlit > /dev/null 2>&1

# On crÃ©e le fichier Python de l'interface dynamiquement
cat <<EOF > dashboard.py
import streamlit as st
import subprocess
import requests
import json

st.set_page_config(layout="wide", page_title="Agent Kernel Interface")

st.title("âš¡ Agent Kernel : God Mode")

# Layout: Colonne de gauche (Chat), Colonne de droite (Terminal/Action)
col1, col2 = st.columns(2)

with col1:
    st.header("ğŸ’¬ Dialogue avec l'Agent ($MODEL_NAME)")
    user_input = st.text_area("Votre ordre :", "Ã‰cris un script Python qui affiche le prix du Bitcoin.")
    
    if st.button("Envoyer l'ordre"):
        with st.spinner('RÃ©flexion en cours...'):
            # Appel Ã  l'API locale d'Ollama
            payload = {
                "model": "$MODEL_NAME",
                "prompt": f"Tu es un expert en code Python. Ã‰cris SEULEMENT le code Python pour rÃ©pondre Ã  cette demande, sans explications : {user_input}",
                "stream": False
            }
            try:
                response = requests.post("http://localhost:11434/api/generate", json=payload)
                generated_code = response.json()['response']
                st.session_state['code'] = generated_code
                st.success("Code gÃ©nÃ©rÃ© !")
            except Exception as e:
                st.error(f"Erreur Ollama: {e}")

with col2:
    st.header("ğŸ–¥ï¸ Kernel (Environnement IsolÃ©)")
    
    if 'code' in st.session_state:
        st.subheader("Code proposÃ© par l'IA :")
        code_to_run = st.text_area("Ã‰diteur", st.session_state['code'], height=200)
        
        # Sauvegarde dans le rootfs
        if st.button("ğŸš€ ExÃ©cuter dans le Kernel"):
            # 1. Ã‰crire le fichier DANS le systÃ¨me de fichiers isolÃ©
            with open("rootfs/home/agent_task.py", "w") as f:
                f.write(code_to_run)
            
            # 2. ExÃ©cuter via chroot
            try:
                result = subprocess.run(
                    ["sudo", "chroot", "rootfs", "python3", "/home/agent_task.py"],
                    capture_output=True, text=True, timeout=10
                )
                st.code(result.stdout, language="bash")
                if result.stderr:
                    st.error(f"Erreur Kernel : {result.stderr}")
            except Exception as e:
                st.error(f"Erreur d'exÃ©cution : {e}")

EOF

# --- 5. CHECKLIST FINALE ---
echo "ğŸ” DIAGNOSTIC FINAL :"

# Test RÃ©seau
if sudo chroot rootfs ping -c 1 google.com > /dev/null 2>&1; then
    echo "   âœ… RÃ©seau Kernel : CONNECTÃ‰"
else
    echo "   âŒ RÃ©seau Kernel : DÃ‰CONNECTÃ‰"
fi

# Test Python Interne
if sudo chroot rootfs python3 /home/health_check.py | grep -q "OPÃ‰RATIONNEL"; then
    echo "   âœ… Environnement Python : PRÃŠT"
else
    echo "   âŒ Environnement Python : CORROMPU"
fi

# Test Ollama
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "   âœ… Cerveau IA (Ollama) : ACTIF"
else
    echo "   âŒ Cerveau IA : INACTIF"
fi

echo ""
echo "âœ¨ SETUP TERMINÃ‰ AVEC SUCCÃˆS !"
echo "ğŸ‘‰ Pour lancer l'interface, tape : streamlit run dashboard.py"
echo "   (GitHub Codespaces ouvrira automatiquement un nouvel onglet)"
